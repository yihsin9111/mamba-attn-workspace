{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"]='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-02 06:19:08.933490: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from mamba_ssm.models.mixer_seq_simple import MambaLMHeadModel\n",
    "from lm_eval.models.huggingface import HFLM\n",
    "from lm_eval.api.model import LM\n",
    "from lm_eval.api.registry import register_model\n",
    "import matplotlib.pyplot as plt\n",
    "def normalize_attn_mat(attn_mat):\n",
    "    return (attn_mat - torch.min(attn_mat)) / (torch.max(attn_mat) - torch.min(attn_mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and load a pretrained Mamba-based LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MambaEvalWrapper(HFLM):\n",
    "    AUTO_MODEL_CLASS = transformers.AutoModelForCausalLM\n",
    "    def __init__(self, pretrained=\"state-spaces/mamba-2.8b\", max_length=2048, batch_size=None, device=\"cuda\",dtype=torch.float16):\n",
    "        LM.__init__(self)\n",
    "        self._model = MambaLMHeadModel.from_pretrained(pretrained, device=device, dtype=dtype)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\")\n",
    "        self.tokenizer.pad_token_id = self.tokenizer.eos_token_id\n",
    "        self.vocab_size = self.tokenizer.vocab_size\n",
    "        self._batch_size = int(batch_size) if batch_size is not None else 64\n",
    "        self._max_length = max_length\n",
    "        self._device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mamba2EvalWrapper(HFLM):\n",
    "    AUTO_MODEL_CLASS = transformers.AutoModelForCausalLM\n",
    "    def __init__(self, pretrained=\"state-spaces/mamba2-2.7b\", max_length=2048, batch_size=None, device=\"cuda\",dtype=torch.float16):\n",
    "        LM.__init__(self)\n",
    "        print(\"initializing mamba2\")\n",
    "        self._model = MambaLMHeadModel.from_pretrained(pretrained, device=device, dtype=dtype)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\")\n",
    "        self.tokenizer.pad_token_id = self.tokenizer.eos_token_id\n",
    "        self.vocab_size = self.tokenizer.vocab_size\n",
    "        self._batch_size = int(batch_size) if batch_size is not None else 64\n",
    "        self._max_length = max_length\n",
    "        self._device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing mamba2\n",
      "initializa LMHead model new version 2024\n"
     ]
    }
   ],
   "source": [
    "model = Mamba2EvalWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Alice was beginning to get very tired of sitting by her sister on the bank\"#, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, “and what is the use of a book,” thought Alice “without pictures or conversations?” So she was considering in her own mind (as well as she could, for the hot day made her feel very sleepy and stupid), whether the pleasure of making a daisy-chain would be worth the trouble of getting up and picking the daisies, when suddenly a White Rabbit with pink eyes\"# ran close by her. There was nothing so very remarkable in that; nor did Alice think it so very much out of the way to hear the Rabbit say to itself, “Oh dear! Oh dear! I shall be late!” (when she thought it over afterwards, it occurred to her that she ought to have wondered at this, but at the time it all seemed quite natural); but when the Rabbit actually took a watch out of its waistcoat-pocket, and looked at it, and then hurried on, Alice started to her feet, for it flashed across her mind that she had never before seen a rabbit with either a waistcoat-pocket, or a watch to take out of it, and burning with curiosity, she ran across the field after it, and fortunately was just in time to see it pop down a large rabbit-hole under the hedge. In another moment down went Alice after it, never once considering how in the world she was to get out again. The rabbit-hole went straight on like a tunnel for some way, and then dipped suddenly down, so suddenly that Alice had not a moment to think about stopping herself before she found herself falling down a very deep well. Either the well was very deep, or she fell very slowly, for she had plenty of time as she went down to look about her and to wonder what was going to happen next. First, she tried to look down and make out what she was coming to, but it was too dark to see anything; then she looked at the sides of the well, and noticed that they were filled with cupboards and book-shelves; here and there she saw maps and pictures hung upon pegs. She took down a jar from one of the shelves as she passed; it was labelled “ORANGE MARMALADE”, but to her great disappointment it was empty: she did not like to drop the jar for fear of killing somebody underneath, so managed to put it\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"sorry to bother, but this pie tastes so good\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"How are you today?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction of Mamba Attention Matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = model.tokenizer(prompt, return_tensors=\"pt\")['input_ids'].cuda()\n",
    "selected_chan = [1,2,3,4,5,6,7]\n",
    "selected_layer = 8\n",
    "model._model.backbone.layers[selected_layer].mixer.compute_attn_matrix = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._model = model._model.cuda()\n",
    "out = model._model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MambaLMHeadModel(\n",
      "  (backbone): MixerModel(\n",
      "    (embedding): Embedding(50288, 2560)\n",
      "    (layers): ModuleList(\n",
      "      (0-63): 64 x Block(\n",
      "        (norm): RMSNorm()\n",
      "        (mixer): Mamba2(\n",
      "          (in_proj): Linear(in_features=2560, out_features=10576, bias=False)\n",
      "          (conv1d): Conv1d(5376, 5376, kernel_size=(4,), stride=(1,), padding=(3,), groups=5376)\n",
      "          (act): SiLU()\n",
      "          (norm): RMSNorm()\n",
      "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm_f): RMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2560, out_features=50288, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model._model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = out.logits.argmax(dim=2).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' to', ' you', ' doing', '?', '  ']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tokenizer.batch_decode(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 50288])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  350,   275,   247,   281,  1928,   247, 11870,   273,   253,   275,\n",
       "          253,  7586,   434,   253,   187,   273], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Mamba2' object has no attribute 'attn_mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m attn_mat \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mselected_layer\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmixer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn_mat\u001b[49m\n\u001b[1;32m      2\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(selected_chan), figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(selected_chan):\n",
      "File \u001b[0;32m~/miniforge3/envs/imb/lib/python3.10/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Mamba2' object has no attribute 'attn_mat'"
     ]
    }
   ],
   "source": [
    "attn_mat = model._model.backbone.layers[selected_layer].mixer.attn_mat\n",
    "fig, axs = plt.subplots(1, len(selected_chan), figsize=(10,10))\n",
    "for i,c in enumerate(selected_chan):\n",
    "    curr_attn_mat = normalize_attn_mat(attn_mat[0,c,:,:].abs())\n",
    "    axs[i].imshow(curr_attn_mat.cpu().detach().numpy())\n",
    "    axs[i].axis('off')\n",
    "model._model.backbone.layers[selected_layer].mixer.compute_attn_matrix = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction of S6 Attention Matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model._model.backbone.layers[selected_layer].mixer.compute_attn_matrix = True # mixer is a mamba block\n",
    "model._model.backbone.layers[selected_layer].mixer.old_attention = True\n",
    "model._model = model._model.cuda()\n",
    "out = model._model(input_tensor)\n",
    "attn_mat = model._model.backbone.layers[selected_layer].mixer.attn_mat # from mamba_inner_fn\n",
    "fig, axs = plt.subplots(1, len(selected_chan), figsize=(10,10))\n",
    "for i,c in enumerate(selected_chan):\n",
    "    curr_attn_mat = normalize_attn_mat(attn_mat[0,c,:,:].abs())\n",
    "    axs[i].imshow(curr_attn_mat.cpu().detach().numpy())\n",
    "    axs[i].axis('off')\n",
    "model._model.backbone.layers[selected_layer].mixer.compute_attn_matrix = False\n",
    "model._model.backbone.layers[selected_layer].mixer.old_attention = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
